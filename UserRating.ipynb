{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ok_end\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "DR = pd.read_csv('DR.csv')\n",
    "\n",
    "def UpdateList(L):\n",
    "    return L/max(L)\n",
    "\n",
    "PostTagList = ['CC','CD','DT','EX','FW','IN','JJ','JJR','JJS','LS','MD','NN','NNS','NNP','NNPS','PDT','POS','PRP','PRP1','RB','RBR','RBS','RP','TO','UH','VB','VBD','VBG','VBN','VBZ','WDT','WP','WP1','WRB']\n",
    "\n",
    "#print DR.columns\n",
    "#print DR.dtypes\n",
    "\n",
    "for PS in PostTagList:\n",
    "#     print PS\n",
    "#     print max(DR[PS])\n",
    "    DR[PS] = UpdateList(DR[PS])\n",
    "#     print max(DR[PS])\n",
    "#     print \"\"\n",
    "    \n",
    "print 'ok_end'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ok_end\n"
     ]
    }
   ],
   "source": [
    "#Drop Rows that Have an Error in the 'Useful_Reviews'\n",
    "inx = []\n",
    "\n",
    "for i in range(0,len(DR)):\n",
    "    try:\n",
    "        k = float(DR.iloc[i,8])\n",
    "    except:\n",
    "        inx.append(i)\n",
    "        \n",
    "DR = DR.drop(DR.index[inx])\n",
    "\n",
    "print 'ok_end'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ok_end\n"
     ]
    }
   ],
   "source": [
    "#Drop the first two columns from DR and assign the data frame to DR_Final\n",
    "DR_Final = DR.drop(['Unnamed: 0','Unnamed: 0.1'],axis=1)\n",
    "\n",
    "# print DR_Final.shape\n",
    "# print DR_Final.columns\n",
    "\n",
    "print 'ok_end'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "162732\n",
      "203\n",
      "ok_end\n"
     ]
    }
   ],
   "source": [
    "print len(DR_Final)\n",
    "print len(inx)\n",
    "\n",
    "print 'ok_end'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ok_end\n"
     ]
    }
   ],
   "source": [
    "#Coerce 'Useful_Reviews' to float\n",
    "DR_Final['Useful_Reviews'] = pd.to_numeric(DR_Final['Useful_Reviews'],errors='coerce')\n",
    "\n",
    "#DR_Sub for Correlation_Matrix\n",
    "DR_Sub = DR_Final.iloc[:,[2,5,6,8,11,12,13,14,15,16,17,18,19,20,21,22,23,24,25,26,27,28,29,30,31,32,34,35,36,37,38,39,40,41,42,43,44,45,46,47,49,50,51]]\n",
    "\n",
    "print 'ok_end'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize Correlation_Matrix from DR_Sub\n",
    "\n",
    "from pandas import set_option\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "%matplotlib tk\n",
    "\n",
    "set_option('precision',1)\n",
    "# print DR_New.corr(method='pearson')\n",
    "\n",
    "fig = plt.figure()\n",
    "ax = fig.add_subplot(111)\n",
    "cax = ax.matshow(DR_Sub.corr(),vmin=-1,vmax=1,interpolation='none')\n",
    "fig.colorbar(cax)\n",
    "ticks = np.arange(0,44,1)\n",
    "ax.set_xticks(ticks)\n",
    "ax.set_yticks(ticks)\n",
    "plt.show()\n",
    "\n",
    "print 'ok_end'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print DR_Sub.columns\n",
    "print DR_Sub.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot Histograms for each variable attribute in DR_Sub\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib tk\n",
    "\n",
    "# print type(ClevelandHD.iloc[1,1])\n",
    "\n",
    "ax = DR_Sub.iloc[0:len(DR_Sub),41].plot.hist(color='red')\n",
    "ax.set_xlabel('Polarity',size=20,fontweight='bold')\n",
    "ax.tick_params(axis='both',labelsize=15)\n",
    "# ax.set_xticklabels(ax.get_xticks(),fontweight='bold')\n",
    "# ax.set_yticklabels(ax.get_yticks(),fontweight='bold')\n",
    "ax.set_ylabel('Counts',size=20,fontweight='bold')\n",
    "ax.set_title('Distribution of Polarity',fontsize=20,fontweight='bold')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Model: Define the Model for (1) Major Interactions or (2) User Rating\n",
    "\n",
    "from sklearn.model_selection import train_test_split, KFold, cross_val_score\n",
    "from sklearn.linear_model import LogisticRegression, LinearRegression\n",
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.linear_model import Lasso\n",
    "from sklearn.linear_model import ElasticNet\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "from sklearn.svm import SVR\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "#Ignore column '5' to predict 'UserRating'\n",
    "DR_Sub_X = DR_Final.iloc[:,[2,6,8,11,12,13,14,15,16,17,18,19,20,21,22,23,24,25,26,27,28,29,30,31,32,34,35,36,37,38,39,40,41,42,43,44,45,46,47,49,50,51]]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Use column '5' to predict 'UserRating'\n",
    "DR_Sub_Y = DR_Final.iloc[:,5]\n",
    "\n",
    "DRSubXMean = DR_Sub_X.mean()\n",
    "DRSubYMean = DR_Sub_Y.mean()\n",
    "\n",
    "seed = 11\n",
    "validation_size = 0.2\n",
    "\n",
    "for i in range(0,len(DRSubXMean)):\n",
    "    DR_Sub_X[DR_Sub_X.columns[i]] = DR_Sub_X[DR_Sub_X.columns[i]].fillna(DRSubXMean[i])\n",
    "    \n",
    "DR_Sub_Y = DR_Sub_Y.fillna(DRSubYMean)\n",
    "    \n",
    "DR_Sub_X = DR_Sub_X.values\n",
    "DR_Sub_Y = DR_Sub_Y.values\n",
    "\n",
    "X_train, X_validation,Y_train,Y_validation = train_test_split(DR_Sub_X,DR_Sub_Y,test_size=validation_size,random_state=seed)\n",
    "\n",
    "# Drop '5' for 'UserRating' model\n",
    "index = [2,6,8,11,12,13,14,15,16,17,18,19,20,21,22,23,24,25,26,27,28,29,30,31,32,34,35,36,37,38,39,40,41,42,43,44,45,46,47,49,50,51]\n",
    "\n",
    "# Assign the model 'UserRating'\n",
    "modelusecase = [5]\n",
    "\n",
    "colnames_X = DR_Final.columns[index]\n",
    "colnames_Y = DR_Final.columns[modelusecase]\n",
    "\n",
    "X_train = pd.DataFrame(X_train)\n",
    "X_train.columns = colnames_X\n",
    "X_train.to_csv('X_train-UsrRat.csv')\n",
    "\n",
    "Y_train = pd.DataFrame(Y_train)\n",
    "Y_train.columns = colnames_Y\n",
    "Y_train.to_csv('Y_train-UsrRat.csv')\n",
    "\n",
    "X_validation = pd.DataFrame(X_validation)\n",
    "X_validation.columns = colnames_X\n",
    "X_validation.to_csv('X_validation-UsrRat.csv')\n",
    "\n",
    "Y_validation = pd.DataFrame(Y_validation)\n",
    "Y_validation.columns = colnames_Y\n",
    "Y_validation.to_csv('Y_validation-UsrRat.csv')\n",
    "\n",
    "print 'ok_end'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(130185, 42) (130185, 1)\n",
      "Index([u'FDA_Alerts', u'Useful_Reviews', u'NReviews', u'Major', u'Moderate',\n",
      "       u'Minor', u'DurationCategory', u'CC', u'CD', u'DT', u'EX', u'FW', u'IN',\n",
      "       u'JJ', u'JJR', u'JJS', u'LS', u'MD', u'NN', u'NNS', u'NNP', u'NNPS',\n",
      "       u'PDT', u'POS', u'PRP', u'RB', u'RBR', u'RBS', u'RP', u'TO', u'UH',\n",
      "       u'VB', u'VBD', u'VBG', u'VBN', u'VBP', u'VBZ', u'WDT', u'WP', u'WRB',\n",
      "       u'Polarity', u'Subjectivity'],\n",
      "      dtype='object')\n",
      "Index([u'UserRating'], dtype='object')\n",
      "Index([u'FDA_Alerts', u'Useful_Reviews', u'NReviews', u'Major', u'Moderate',\n",
      "       u'Minor', u'DurationCategory', u'CC', u'CD', u'DT', u'EX', u'FW', u'IN',\n",
      "       u'JJ', u'JJR', u'JJS', u'LS', u'MD', u'NN', u'NNS', u'NNP', u'NNPS',\n",
      "       u'PDT', u'POS', u'PRP', u'RB', u'RBR', u'RBS', u'RP', u'TO', u'UH',\n",
      "       u'VB', u'VBD', u'VBG', u'VBN', u'VBP', u'VBZ', u'WDT', u'WP', u'WRB',\n",
      "       u'Polarity', u'Subjectivity'],\n",
      "      dtype='object')\n",
      "ok_end\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "X_train = pd.read_csv('X_train-UsrRat.csv').drop(['Unnamed: 0'],axis=1)\n",
    "Y_train = pd.read_csv('Y_train-UsrRat.csv').drop(['Unnamed: 0'],axis=1)\n",
    "X_validation = pd.read_csv('X_validation-UsrRat.csv').drop(['Unnamed: 0'],axis=1)\n",
    "Y_validation = pd.read_csv('Y_validation-UsrRat.csv').drop(['Unnamed: 0'],axis=1)\n",
    "\n",
    "print X_train.shape, Y_train.shape\n",
    "print X_train.columns\n",
    "print Y_train.columns\n",
    "\n",
    "print X_train.columns\n",
    "\n",
    "print 'ok_end'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import Statements\n",
    "from sklearn.model_selection import train_test_split, KFold, cross_val_score\n",
    "from sklearn.linear_model import LogisticRegression, LinearRegression\n",
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.linear_model import Lasso\n",
    "from sklearn.linear_model import ElasticNet\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "from sklearn.svm import SVR\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.pipeline import Pipeline\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ok\n",
      "LR1: -8.179020 (0.125989)\n",
      "LASSO: -9.604828 (0.099259)\n",
      "EN: -9.518885 (0.096425)\n",
      "KNN: -9.229014 (0.121850)\n",
      "CART: -10.633969 (0.141135)\n",
      "ok_end\n"
     ]
    }
   ],
   "source": [
    "#Spotcheck Algorithms\n",
    "validation_size = 0.2\n",
    "seed = 11\n",
    "\n",
    "num_folds = 10\n",
    "scoring = 'neg_mean_squared_error'\n",
    "\n",
    "models = []\n",
    "models.append(('LR1',LinearRegression()))\n",
    "models.append(('LASSO',Lasso()))\n",
    "models.append(('EN',ElasticNet()))\n",
    "models.append(('KNN',KNeighborsRegressor()))\n",
    "models.append(('CART',DecisionTreeRegressor()))\n",
    "# models.append(('SVR',SVR()))\n",
    "\n",
    "results = []\n",
    "names = []\n",
    "print 'ok'\n",
    "for name,model in models:\n",
    "#     print name, model\n",
    "    kfold = KFold(n_splits=num_folds,random_state=seed)\n",
    "    cv_results = cross_val_score(model,X_train,Y_train,cv=kfold,scoring=scoring)\n",
    "    results.append(cv_results)\n",
    "    names.append(name)\n",
    "    msg = \"%s: %f (%f)\" % (name, cv_results.mean(),cv_results.std())\n",
    "    print msg\n",
    "\n",
    "print 'ok_end'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "%matplotlib tk\n",
    "\n",
    "#Compare Algorithm Responses\n",
    "fig = plt.figure()\n",
    "fig.suptitle(\"Comparison of Algorithms (POS Tag)\",fontsize=20,fontweight='bold')\n",
    "ax = fig.add_subplot(111)\n",
    "plt.boxplot(results)\n",
    "ax.set_xticklabels(names)\n",
    "ax.tick_params(axis='both',labelsize=15)\n",
    "# ax.set_xticklabels(ax.get_xticks(),fontweight='bold')\n",
    "# ax.set_yticklabels(ax.get_yticks(),fontweight='bold')\n",
    "plt.xlabel('Algorithm',size=20,fontweight='bold')\n",
    "plt.ylabel('Neg Mean Squared',size=20,fontweight='bold')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ok\n",
      "ScaledLR: -8.179020 (0.125989)\n",
      "ScaledLASSO: -10.053987 (0.105601)\n",
      "ScaledEN: -9.348817 (0.111418)\n",
      "ScaledCART: -10.636023 (0.214645)\n"
     ]
    }
   ],
   "source": [
    "#Standardize the Data\n",
    "pipelines = []\n",
    "\n",
    "pipelines.append(('ScaledLR',Pipeline([('Scaler',StandardScaler()),('LR',LinearRegression())])))\n",
    "pipelines.append(('ScaledLASSO',Pipeline([('Scaler',StandardScaler()),('LASSO',Lasso())])))\n",
    "pipelines.append(('ScaledEN',Pipeline([('Scaler',StandardScaler()),('EN',ElasticNet())])))\n",
    "# pipelines.append(('ScaledKNN',Pipeline([('Scaler',StandardScaler()),('KNN',KNeighborsRegressor())])))\n",
    "pipelines.append(('ScaledCART',Pipeline([('Scaler',StandardScaler()),('CART',DecisionTreeRegressor())])))\n",
    "\n",
    "results = []\n",
    "names = []\n",
    "print 'ok'\n",
    "for name,model in pipelines:\n",
    "    kfold = KFold(n_splits=num_folds,random_state=seed)\n",
    "    cv_results = cross_val_score(model,X_train,Y_train,cv=kfold,scoring=scoring)\n",
    "    results.append(cv_results)\n",
    "    names.append(name)\n",
    "    msg = \"%s: %f (%f)\" % (name, cv_results.mean(),cv_results.std())\n",
    "    print msg\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Compare Algorithm Responses\n",
    "fig = plt.figure()\n",
    "fig.suptitle(\"Comparison of Algorithms (POS Tag)\",fontsize=20,fontweight='bold')\n",
    "ax = fig.add_subplot(111)\n",
    "plt.boxplot(results)\n",
    "ax.set_xticklabels(names)\n",
    "ax.tick_params(axis='both',labelsize=15)\n",
    "# ax.set_xticklabels(ax.get_xticks(),fontweight='bold')\n",
    "# ax.set_yticklabels(ax.get_yticks(),fontweight='bold')\n",
    "plt.xlabel('Algorithm',size=20,fontweight='bold')\n",
    "plt.ylabel('Neg Mean Squared',size=20,fontweight='bold')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/krishnaveni/anaconda2/lib/python2.7/site-packages/sklearn/utils/validation.py:761: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " ScaledAB: -8.454259 (0.114877)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/krishnaveni/anaconda2/lib/python2.7/site-packages/sklearn/ensemble/forest.py:246: FutureWarning: The default value of n_estimators will change from 10 in version 0.20 to 100 in 0.22.\n",
      "  \"10 in version 0.20 to 100 in 0.22.\", FutureWarning)\n",
      "/home/krishnaveni/anaconda2/lib/python2.7/site-packages/sklearn/pipeline.py:267: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  self._final_estimator.fit(Xt, y, **fit_params)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ScaledRF: -6.045604 (0.111628)\n",
      "ScaledET: -5.403135 (0.106108)\n",
      "ok_end\n"
     ]
    }
   ],
   "source": [
    "#Ensemble Methods\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.ensemble import GradientBoostingRegressor\n",
    "from sklearn.ensemble import ExtraTreesRegressor\n",
    "from sklearn.ensemble import AdaBoostRegressor\n",
    "\n",
    "ensembles = []\n",
    "ensembles.append((' ScaledAB',Pipeline([('Scaler',StandardScaler()),('AB',AdaBoostRegressor())])))\n",
    "# ensembles.append(('ScaledGBM',Pipeline([('Scaler',StandardScaler()),('GBM',GradientBoostingRegressor())])))\n",
    "ensembles.append(('ScaledRF',Pipeline([('Scaler',StandardScaler()),('RF',RandomForestRegressor())])))\n",
    "ensembles.append(('ScaledET',Pipeline([('Scaler',StandardScaler()),('ET',ExtraTreesRegressor())])))\n",
    "\n",
    "seed = 7\n",
    "\n",
    "results = []\n",
    "names = []\n",
    "for name, model in ensembles:\n",
    "    kfold = KFold(n_splits=num_folds, random_state=seed)\n",
    "    cv_results = cross_val_score(model, X_train, Y_train, cv=kfold, scoring=scoring)\n",
    "    results.append(cv_results)\n",
    "    names.append(name)\n",
    "    msg = \"%s: %f (%f)\" % (name, cv_results.mean(), cv_results.std())\n",
    "    print(msg)\n",
    "    \n",
    "print 'ok_end'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Compare Algorithm Responses\n",
    "fig = plt.figure()\n",
    "fig.suptitle(\"Comparison of Algorithms (POS Tag)\",fontsize=20,fontweight='bold')\n",
    "ax = fig.add_subplot(111)\n",
    "plt.boxplot(results)\n",
    "ax.set_xticklabels(names)\n",
    "ax.tick_params(axis='both',labelsize=15)\n",
    "# ax.set_xticklabels(ax.get_xticks(),fontweight='bold')\n",
    "# ax.set_yticklabels(ax.get_yticks(),fontweight='bold')\n",
    "plt.xlabel('Algorithm',size=20,fontweight='bold')\n",
    "plt.ylabel('Neg Mean Squared',size=20,fontweight='bold')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Fine Tune Extra_Trees\n",
    "import numpy as np\n",
    "from sklearn.ensemble import ExtraTreesRegressor\n",
    "\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "seed = 11\n",
    "num_folds = 10\n",
    "scoring = 'neg_mean_squared_error'\n",
    "\n",
    "scaler = StandardScaler().fit(X_train)\n",
    "rescaledX = scaler.transform(X_train)\n",
    "param_grid = dict(n_estimators=np.array([10,50,100,500]))\n",
    "model = ExtraTreesRegressor(random_state=seed)\n",
    "kfold = KFold(n_splits=num_folds,random_state=seed)\n",
    "grid = GridSearchCV(estimator=model,param_grid=param_grid,scoring=scoring,cv=kfold)\n",
    "print 'ok'\n",
    "grid_result = grid.fit(rescaledX,Y_train)\n",
    "\n",
    "print(\"Best: %f using %s\" % (grid_result.best_score_,grid_result.best_params_))\n",
    "means = grid_result.cv_results_['mean_test_score']\n",
    "stds = grid_result.cv_results_['std_test_score']\n",
    "params = grid_result.cv_results_['params']\n",
    "for mean, stdev, param in zip(means,stds,params):\n",
    "    print(\"%f (%f) with: %r\" % (mean,stdev,param))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Compare Fine-Tuned Responses\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib tk\n",
    "\n",
    "fig = plt.figure()\n",
    "fig.suptitle(\"Comparison of Trees (User Rating)\",fontsize=20,fontweight='bold')\n",
    "ax = fig.add_subplot(111)\n",
    "\n",
    "names = ['10','50','100','500']\n",
    "results = [-5.364448,-4.909690,-4.856185,-4.814780]\n",
    "errorbar = [0.093242,0.072308,0.078018,0.075476]\n",
    "\n",
    "plt.errorbar(names, results, errorbar, linestyle='--',marker='^',markersize=15,capsize=20)\n",
    "# ax.set_xticklabels(names)\n",
    "ax.tick_params(axis='both',labelsize=15)\n",
    "# ax.set_xticklabels(ax.get_xticks(),fontweight='bold')\n",
    "# ax.set_yticklabels(ax.get_yticks(),fontweight='bold')\n",
    "plt.xlabel('Number of Estimators',size=20,fontweight='bold')\n",
    "plt.ylabel('Neg Mean Squared',size=20,fontweight='bold')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "param_grid\n",
    "print(\"Best: %f using %s\" % (grid_result.best_score_,grid_result.best_params_))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Execute the final model: ExtraTrees(n_estimators:100) on the validation set\n",
    "\n",
    "from sklearn.ensemble import ExtraTreesRegressor\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "seed = 13\n",
    "ET = ExtraTreesRegressor(n_estimators=100,random_state=seed)\n",
    "ET.fit(X_train,Y_train)\n",
    "predictions = ET.predict(X_validation)\n",
    "print(mean_squared_error(Y_validation,predictions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix, classification_report\n",
    "from sklearn.metrics import explained_variance_score\n",
    "\n",
    "# print(explained_variance_score(Y_validation,predictions))\n",
    "# print(confusion_matrix(Y_validation,predictions))\n",
    "# print(classification_report(Y_validation,predictions))\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
