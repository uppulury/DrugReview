{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index([u'Unnamed: 0', u'Unnamed: 0.1', u'Comment', u'Duration', u'FDA_Alerts',\n",
      "       u'Drug_Class', u'Drug_Name', u'UserRating', u'Useful_Reviews', u'Date',\n",
      "       u'NReviews', u'Drug_Interactions', u'Condition', u'Major', u'Moderate',\n",
      "       u'Minor', u'DurationCategory', u'CC', u'CD', u'DT', u'EX', u'FW', u'IN',\n",
      "       u'JJ', u'JJR', u'JJS', u'LS', u'MD', u'NN', u'NNS', u'NNP', u'NNPS',\n",
      "       u'PDT', u'POS', u'PRP', u'PRP1', u'RB', u'RBR', u'RBS', u'RP', u'TO',\n",
      "       u'UH', u'VB', u'VBD', u'VBG', u'VBN', u'VBP', u'VBZ', u'WDT', u'WP',\n",
      "       u'WP1', u'WRB', u'Polarity', u'Subjectivity'],\n",
      "      dtype='object')\n",
      "Unnamed: 0             int64\n",
      "Unnamed: 0.1           int64\n",
      "Comment               object\n",
      "Duration              object\n",
      "FDA_Alerts           float64\n",
      "Drug_Class            object\n",
      "Drug_Name             object\n",
      "UserRating           float64\n",
      "Useful_Reviews        object\n",
      "Date                  object\n",
      "NReviews               int64\n",
      "Drug_Interactions     object\n",
      "Condition             object\n",
      "Major                float64\n",
      "Moderate             float64\n",
      "Minor                float64\n",
      "DurationCategory       int64\n",
      "CC                   float64\n",
      "CD                   float64\n",
      "DT                   float64\n",
      "EX                   float64\n",
      "FW                   float64\n",
      "IN                   float64\n",
      "JJ                   float64\n",
      "JJR                  float64\n",
      "JJS                  float64\n",
      "LS                   float64\n",
      "MD                   float64\n",
      "NN                   float64\n",
      "NNS                  float64\n",
      "NNP                  float64\n",
      "NNPS                 float64\n",
      "PDT                  float64\n",
      "POS                  float64\n",
      "PRP                  float64\n",
      "PRP1                 float64\n",
      "RB                   float64\n",
      "RBR                  float64\n",
      "RBS                  float64\n",
      "RP                   float64\n",
      "TO                   float64\n",
      "UH                   float64\n",
      "VB                   float64\n",
      "VBD                  float64\n",
      "VBG                  float64\n",
      "VBN                  float64\n",
      "VBP                    int64\n",
      "VBZ                  float64\n",
      "WDT                  float64\n",
      "WP                   float64\n",
      "WP1                  float64\n",
      "WRB                  float64\n",
      "Polarity             float64\n",
      "Subjectivity         float64\n",
      "dtype: object\n",
      "CC\n",
      "1.0\n",
      "1.0\n",
      "\n",
      "CD\n",
      "1.0\n",
      "1.0\n",
      "\n",
      "DT\n",
      "1.0\n",
      "1.0\n",
      "\n",
      "EX\n",
      "1.0\n",
      "1.0\n",
      "\n",
      "FW\n",
      "1.0\n",
      "1.0\n",
      "\n",
      "IN\n",
      "1.0\n",
      "1.0\n",
      "\n",
      "JJ\n",
      "1.0\n",
      "1.0\n",
      "\n",
      "JJR\n",
      "1.0\n",
      "1.0\n",
      "\n",
      "JJS\n",
      "1.0\n",
      "1.0\n",
      "\n",
      "LS\n",
      "1.0\n",
      "1.0\n",
      "\n",
      "MD\n",
      "1.0\n",
      "1.0\n",
      "\n",
      "NN\n",
      "1.0\n",
      "1.0\n",
      "\n",
      "NNS\n",
      "1.0\n",
      "1.0\n",
      "\n",
      "NNP\n",
      "1.0\n",
      "1.0\n",
      "\n",
      "NNPS\n",
      "1.0\n",
      "1.0\n",
      "\n",
      "PDT\n",
      "1.0\n",
      "1.0\n",
      "\n",
      "POS\n",
      "1.0\n",
      "1.0\n",
      "\n",
      "PRP\n",
      "1.0\n",
      "1.0\n",
      "\n",
      "PRP1\n",
      "nan\n",
      "nan\n",
      "\n",
      "RB\n",
      "1.0\n",
      "1.0\n",
      "\n",
      "RBR\n",
      "1.0\n",
      "1.0\n",
      "\n",
      "RBS\n",
      "1.0\n",
      "1.0\n",
      "\n",
      "RP\n",
      "1.0\n",
      "1.0\n",
      "\n",
      "TO\n",
      "1.0\n",
      "1.0\n",
      "\n",
      "UH\n",
      "1.0\n",
      "1.0\n",
      "\n",
      "VB\n",
      "1.0\n",
      "1.0\n",
      "\n",
      "VBD\n",
      "1.0\n",
      "1.0\n",
      "\n",
      "VBG\n",
      "1.0\n",
      "1.0\n",
      "\n",
      "VBN\n",
      "1.0\n",
      "1.0\n",
      "\n",
      "VBZ\n",
      "1.0\n",
      "1.0\n",
      "\n",
      "WDT\n",
      "1.0\n",
      "1.0\n",
      "\n",
      "WP\n",
      "1.0\n",
      "1.0\n",
      "\n",
      "WP1\n",
      "nan\n",
      "nan\n",
      "\n",
      "WRB\n",
      "1.0\n",
      "1.0\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "DR = pd.read_csv('DR.csv')\n",
    "\n",
    "def UpdateList(L):\n",
    "    return L/max(L)\n",
    "\n",
    "PostTagList = ['CC','CD','DT','EX','FW','IN','JJ','JJR','JJS','LS','MD','NN','NNS','NNP','NNPS','PDT','POS','PRP','PRP1','RB','RBR','RBS','RP','TO','UH','VB','VBD','VBG','VBN','VBZ','WDT','WP','WP1','WRB']\n",
    "\n",
    "print DR.columns\n",
    "print DR.dtypes\n",
    "\n",
    "for PS in PostTagList:\n",
    "    print PS\n",
    "    print max(DR[PS])\n",
    "    DR[PS] = UpdateList(DR[PS])\n",
    "    print max(DR[PS])\n",
    "    print \"\"\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Drop Rows that Have an Error in the 'Useful_Reviews'\n",
    "inx = []\n",
    "\n",
    "for i in range(0,len(DR)):\n",
    "    try:\n",
    "        k = float(DR.iloc[i,8])\n",
    "    except:\n",
    "        inx.append(i)\n",
    "        \n",
    "DR = DR.drop(DR.index[inx])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Drop the first two columns from DR and assign the data frame to DR_Final\n",
    "DR_Final = DR.drop(['Unnamed: 0','Unnamed: 0.1'],axis=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "162732\n",
      "203\n"
     ]
    }
   ],
   "source": [
    "print len(DR_Final)\n",
    "print len(inx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Coerce 'Useful_Reviews' to float\n",
    "DR_Final['Useful_Reviews'] = pd.to_numeric(DR_Final['Useful_Reviews'],errors='coerce')\n",
    "\n",
    "#DR_Sub for Correlation_Matrix\n",
    "DR_Sub = DR_Final.iloc[:,[2,5,6,8,11,12,13,14,15,16,17,18,19,20,21,22,23,24,25,26,27,28,29,30,31,32,34,35,36,37,38,39,40,41,42,43,44,45,46,47,49,50,51]]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize Correlation_Matrix from DR_Sub\n",
    "from pandas import set_option\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "%matplotlib tk\n",
    "\n",
    "set_option('precision',1)\n",
    "# print DR_New.corr(method='pearson')\n",
    "\n",
    "fig = plt.figure()\n",
    "ax = fig.add_subplot(111)\n",
    "cax = ax.matshow(DR_Sub.corr(),vmin=-1,vmax=1,interpolation='none')\n",
    "fig.colorbar(cax)\n",
    "ticks = np.arange(0,44,1)\n",
    "ax.set_xticks(ticks)\n",
    "ax.set_yticks(ticks)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print DR_Sub.columns\n",
    "print DR_Sub.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot Histograms for each variable attribute in DR_Sub\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib tk\n",
    "\n",
    "ax = DR_Sub.iloc[0:len(DR_Sub),41].plot.hist(color='red')\n",
    "ax.set_xlabel('Polarity',size=20,fontweight='bold')\n",
    "ax.tick_params(axis='both',labelsize=15)\n",
    "# ax.set_xticklabels(ax.get_xticks(),fontweight='bold')\n",
    "# ax.set_yticklabels(ax.get_yticks(),fontweight='bold')\n",
    "ax.set_ylabel('Counts',size=20,fontweight='bold')\n",
    "ax.set_title('Distribution of Polarity',fontsize=20,fontweight='bold')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Model: Define the Model for 'Major Interactions'\n",
    "\n",
    "from sklearn.model_selection import train_test_split, KFold, cross_val_score\n",
    "from sklearn.linear_model import LogisticRegression, LinearRegression\n",
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.linear_model import Lasso\n",
    "from sklearn.linear_model import ElasticNet\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "from sklearn.svm import SVR\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "#To predict 'Major Drug Interactions' Ignore column '11'\n",
    "DR_Sub_X = DR_Final.iloc[:,[2,5,6,8,12,13,14,15,16,17,18,19,20,21,22,23,24,25,26,27,28,29,30,31,32,34,35,36,37,38,39,40,41,42,43,44,45,46,47,49,50,51]]\n",
    "\n",
    "#Use column '11' to predict 'Major Drug Interactions'\n",
    "DR_Sub_Y = DR_Final.iloc[:,11]\n",
    "\n",
    "DRSubXMean = DR_Sub_X.mean()\n",
    "DRSubYMean = DR_Sub_Y.mean()\n",
    "\n",
    "seed = 11\n",
    "validation_size = 0.2\n",
    "\n",
    "for i in range(0,len(DRSubXMean)):\n",
    "    DR_Sub_X[DR_Sub_X.columns[i]] = DR_Sub_X[DR_Sub_X.columns[i]].fillna(DRSubXMean[i])\n",
    "    \n",
    "DR_Sub_Y = DR_Sub_Y.fillna(DRSubYMean)\n",
    "    \n",
    "DR_Sub_X = DR_Sub_X.values\n",
    "DR_Sub_Y = DR_Sub_Y.values\n",
    "\n",
    "X_train, X_validation,Y_train,Y_validation = train_test_split(DR_Sub_X,DR_Sub_Y,test_size=validation_size,random_state=seed)\n",
    "\n",
    "# Drop '11' for 'Major Interactions' model\n",
    "index = [2,5,6,8,12,13,14,15,16,17,18,19,20,21,22,23,24,25,26,27,28,29,30,31,32,34,35,36,37,38,39,40,41,42,43,44,45,46,47,49,50,51]\n",
    "\n",
    "# Assign the model either 'Major'\n",
    "modelusecase = [11]\n",
    "\n",
    "colnames_X = DR_Final.columns[index]\n",
    "colnames_Y = DR_Final.columns[modelusecase]\n",
    "\n",
    "X_train = pd.DataFrame(X_train)\n",
    "X_train.columns = colnames_X\n",
    "X_train.to_csv('X_train-MajInt.csv')\n",
    "\n",
    "Y_train = pd.DataFrame(Y_train)\n",
    "Y_train.columns = colnames_Y\n",
    "Y_train.to_csv('Y_train-MajInt.csv')\n",
    "\n",
    "X_validation = pd.DataFrame(X_validation)\n",
    "X_validation.columns = colnames_X\n",
    "X_validation.to_csv('X_validation-MajInt.csv')\n",
    "\n",
    "Y_validation = pd.DataFrame(Y_validation)\n",
    "Y_validation.columns = colnames_Y\n",
    "Y_validation.to_csv('Y_validation-MajInt.csv')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(130185, 42) (130185, 1)\n",
      "Index([u'FDA_Alerts', u'UserRating', u'Useful_Reviews', u'NReviews',\n",
      "       u'Moderate', u'Minor', u'DurationCategory', u'CC', u'CD', u'DT', u'EX',\n",
      "       u'FW', u'IN', u'JJ', u'JJR', u'JJS', u'LS', u'MD', u'NN', u'NNS',\n",
      "       u'NNP', u'NNPS', u'PDT', u'POS', u'PRP', u'RB', u'RBR', u'RBS', u'RP',\n",
      "       u'TO', u'UH', u'VB', u'VBD', u'VBG', u'VBN', u'VBP', u'VBZ', u'WDT',\n",
      "       u'WP', u'WRB', u'Polarity', u'Subjectivity'],\n",
      "      dtype='object')\n",
      "Index([u'Major'], dtype='object')\n",
      "Index([u'FDA_Alerts', u'UserRating', u'Useful_Reviews', u'NReviews',\n",
      "       u'Moderate', u'Minor', u'DurationCategory', u'CC', u'CD', u'DT', u'EX',\n",
      "       u'FW', u'IN', u'JJ', u'JJR', u'JJS', u'LS', u'MD', u'NN', u'NNS',\n",
      "       u'NNP', u'NNPS', u'PDT', u'POS', u'PRP', u'RB', u'RBR', u'RBS', u'RP',\n",
      "       u'TO', u'UH', u'VB', u'VBD', u'VBG', u'VBN', u'VBP', u'VBZ', u'WDT',\n",
      "       u'WP', u'WRB', u'Polarity', u'Subjectivity'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "X_train = pd.read_csv('X_train-MajInt.csv').drop(['Unnamed: 0'],axis=1)\n",
    "Y_train = pd.read_csv('Y_train-MajInt.csv').drop(['Unnamed: 0'],axis=1)\n",
    "X_validation = pd.read_csv('X_validation-MajInt.csv').drop(['Unnamed: 0'],axis=1)\n",
    "Y_validation = pd.read_csv('Y_validation-MajInt.csv').drop(['Unnamed: 0'],axis=1)\n",
    "\n",
    "print X_train.shape, Y_train.shape\n",
    "print X_train.columns\n",
    "print Y_train.columns\n",
    "\n",
    "print X_train.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import Statements\n",
    "from sklearn.model_selection import train_test_split, KFold, cross_val_score\n",
    "from sklearn.linear_model import LogisticRegression, LinearRegression\n",
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.linear_model import Lasso\n",
    "from sklearn.linear_model import ElasticNet\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "from sklearn.svm import SVR\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.pipeline import Pipeline\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ok\n",
      "LR1: -11723.231415 (135.647873)\n",
      "LASSO: -11786.750272 (142.219988)\n",
      "EN: -11792.753546 (140.402347)\n",
      "KNN: -193.600949 (47.808853)\n",
      "CART: -7.840296 (4.603752)\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#Spotcheck Algorithms\n",
    "validation_size = 0.2\n",
    "seed = 11\n",
    "\n",
    "num_folds = 10\n",
    "scoring = 'neg_mean_squared_error'\n",
    "\n",
    "models = []\n",
    "models.append(('LR1',LinearRegression()))\n",
    "models.append(('LASSO',Lasso()))\n",
    "models.append(('EN',ElasticNet()))\n",
    "models.append(('KNN',KNeighborsRegressor()))\n",
    "models.append(('CART',DecisionTreeRegressor()))\n",
    "# models.append(('SVR',SVR()))\n",
    "\n",
    "results = []\n",
    "names = []\n",
    "print 'ok'\n",
    "for name,model in models:\n",
    "#     print name, model\n",
    "    kfold = KFold(n_splits=num_folds,random_state=seed)\n",
    "    cv_results = cross_val_score(model,X_train,Y_train,cv=kfold,scoring=scoring)\n",
    "    results.append(cv_results)\n",
    "    names.append(name)\n",
    "    msg = \"%s: %f (%f)\" % (name, cv_results.mean(),cv_results.std())\n",
    "    print msg\n",
    "\n",
    "print \"\"\n",
    "print \"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "%matplotlib tk\n",
    "\n",
    "#Compare Algorithm Responses\n",
    "fig = plt.figure()\n",
    "fig.suptitle(\"Comparison of Algorithms (POS Tag)\",fontsize=20,fontweight='bold')\n",
    "ax = fig.add_subplot(111)\n",
    "plt.boxplot(results)\n",
    "ax.set_xticklabels(names)\n",
    "ax.tick_params(axis='both',labelsize=15)\n",
    "# ax.set_xticklabels(ax.get_xticks(),fontweight='bold')\n",
    "# ax.set_yticklabels(ax.get_yticks(),fontweight='bold')\n",
    "plt.xlabel('Algorithm',size=20,fontweight='bold')\n",
    "plt.ylabel('Neg Mean Squared',size=20,fontweight='bold')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ok\n",
      "ScaledLR: -11723.231415 (135.647873)\n",
      "ScaledLASSO: -11754.439208 (137.252720)\n",
      "ScaledEN: -12144.124922 (123.577845)\n",
      "ScaledCART: -7.764258 (3.303237)\n",
      "ok_end\n"
     ]
    }
   ],
   "source": [
    "#Standardize the Data\n",
    "pipelines = []\n",
    "\n",
    "pipelines.append(('ScaledLR',Pipeline([('Scaler',StandardScaler()),('LR',LinearRegression())])))\n",
    "pipelines.append(('ScaledLASSO',Pipeline([('Scaler',StandardScaler()),('LASSO',Lasso())])))\n",
    "pipelines.append(('ScaledEN',Pipeline([('Scaler',StandardScaler()),('EN',ElasticNet())])))\n",
    "# pipelines.append(('ScaledKNN',Pipeline([('Scaler',StandardScaler()),('KNN',KNeighborsRegressor())])))\n",
    "pipelines.append(('ScaledCART',Pipeline([('Scaler',StandardScaler()),('CART',DecisionTreeRegressor())])))\n",
    "\n",
    "results = []\n",
    "names = []\n",
    "print 'ok'\n",
    "for name,model in pipelines:\n",
    "    kfold = KFold(n_splits=num_folds,random_state=seed)\n",
    "    cv_results = cross_val_score(model,X_train,Y_train,cv=kfold,scoring=scoring)\n",
    "    results.append(cv_results)\n",
    "    names.append(name)\n",
    "    msg = \"%s: %f (%f)\" % (name, cv_results.mean(),cv_results.std())\n",
    "    print msg\n",
    "    \n",
    "print 'ok_end'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Compare Algorithm Responses\n",
    "fig = plt.figure()\n",
    "fig.suptitle(\"Comparison of Algorithms (POS Tag)\",fontsize=20,fontweight='bold')\n",
    "ax = fig.add_subplot(111)\n",
    "plt.boxplot(results)\n",
    "ax.set_xticklabels(names)\n",
    "ax.tick_params(axis='both',labelsize=15)\n",
    "# ax.set_xticklabels(ax.get_xticks(),fontweight='bold')\n",
    "# ax.set_yticklabels(ax.get_yticks(),fontweight='bold')\n",
    "plt.xlabel('Algorithm',size=20,fontweight='bold')\n",
    "plt.ylabel('Neg Mean Squared',size=20,fontweight='bold')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/krishnaveni/anaconda2/lib/python2.7/site-packages/sklearn/utils/validation.py:761: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " ScaledAB: -9711.512055 (739.890836)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/krishnaveni/anaconda2/lib/python2.7/site-packages/sklearn/ensemble/forest.py:246: FutureWarning: The default value of n_estimators will change from 10 in version 0.20 to 100 in 0.22.\n",
      "  \"10 in version 0.20 to 100 in 0.22.\", FutureWarning)\n",
      "/home/krishnaveni/anaconda2/lib/python2.7/site-packages/sklearn/pipeline.py:267: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  self._final_estimator.fit(Xt, y, **fit_params)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ScaledRF: -9.173086 (5.084887)\n",
      "ScaledET: -7.257761 (2.145993)\n",
      "ok_end\n"
     ]
    }
   ],
   "source": [
    "#Ensemble Methods\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.ensemble import GradientBoostingRegressor\n",
    "from sklearn.ensemble import ExtraTreesRegressor\n",
    "from sklearn.ensemble import AdaBoostRegressor\n",
    "\n",
    "ensembles = []\n",
    "ensembles.append((' ScaledAB',Pipeline([('Scaler',StandardScaler()),('AB',AdaBoostRegressor())])))\n",
    "# ensembles.append(('ScaledGBM',Pipeline([('Scaler',StandardScaler()),('GBM',GradientBoostingRegressor())])))\n",
    "ensembles.append(('ScaledRF',Pipeline([('Scaler',StandardScaler()),('RF',RandomForestRegressor())])))\n",
    "ensembles.append(('ScaledET',Pipeline([('Scaler',StandardScaler()),('ET',ExtraTreesRegressor())])))\n",
    "\n",
    "seed = 7\n",
    "\n",
    "results = []\n",
    "names = []\n",
    "for name, model in ensembles:\n",
    "    kfold = KFold(n_splits=num_folds, random_state=seed)\n",
    "    cv_results = cross_val_score(model, X_train, Y_train, cv=kfold, scoring=scoring)\n",
    "    results.append(cv_results)\n",
    "    names.append(name)\n",
    "    msg = \"%s: %f (%f)\" % (name, cv_results.mean(), cv_results.std())\n",
    "    print(msg)\n",
    "    \n",
    "print 'ok_end'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print len(cv_results)\n",
    "print results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Compare Algorithm Responses\n",
    "fig = plt.figure()\n",
    "fig.suptitle(\"Comparison of Algorithms (POS Tag)\",fontsize=20,fontweight='bold')\n",
    "ax = fig.add_subplot(111)\n",
    "plt.boxplot(results)\n",
    "ax.set_xticklabels(names)\n",
    "ax.tick_params(axis='both',labelsize=15)\n",
    "# ax.set_xticklabels(ax.get_xticks(),fontweight='bold')\n",
    "# ax.set_yticklabels(ax.get_yticks(),fontweight='bold')\n",
    "plt.xlabel('Algorithm',size=20,fontweight='bold')\n",
    "plt.ylabel('Neg Mean Squared',size=20,fontweight='bold')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Fine Tune Extra_Trees\n",
    "import numpy as np\n",
    "from sklearn.ensemble import ExtraTreesRegressor\n",
    "\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "seed = 11\n",
    "num_folds = 10\n",
    "scoring = 'neg_mean_squared_error'\n",
    "\n",
    "scaler = StandardScaler().fit(X_train)\n",
    "rescaledX = scaler.transform(X_train)\n",
    "param_grid = dict(n_estimators=np.array([10,50,100,500]))\n",
    "model = ExtraTreesRegressor(random_state=seed)\n",
    "kfold = KFold(n_splits=num_folds,random_state=seed)\n",
    "grid = GridSearchCV(estimator=model,param_grid=param_grid,scoring=scoring,cv=kfold)\n",
    "print 'ok'\n",
    "grid_result = grid.fit(rescaledX,Y_train)\n",
    "\n",
    "print(\"Best: %f using %s\" % (grid_result.best_score_,grid_result.best_params_))\n",
    "means = grid_result.cv_results_['mean_test_score']\n",
    "stds = grid_result.cv_results_['std_test_score']\n",
    "params = grid_result.cv_results_['params']\n",
    "for mean, stdev, param in zip(means,stds,params):\n",
    "    print(\"%f (%f) with: %r\" % (mean,stdev,param))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Compare Fine-Tuned Responses\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib tk\n",
    "\n",
    "fig = plt.figure()\n",
    "fig.suptitle(\"Comparison of Trees (Major Interactions)\",fontsize=20,fontweight='bold')\n",
    "ax = fig.add_subplot(111)\n",
    "\n",
    "names = ['10','50','100','500']\n",
    "results = [-7.740830, -5.211410, -4.789472, -4.580332]\n",
    "errorbar = [4.077324, 3.256445, 2.967114, 2.977927]\n",
    "\n",
    "plt.errorbar(names, results, errorbar, linestyle='--',marker='^',markersize=15,capsize=20)\n",
    "# ax.set_xticklabels(names)\n",
    "ax.tick_params(axis='both',labelsize=15)\n",
    "# ax.set_xticklabels(ax.get_xticks(),fontweight='bold')\n",
    "# ax.set_yticklabels(ax.get_yticks(),fontweight='bold')\n",
    "plt.xlabel('Number of Estimators',size=20,fontweight='bold')\n",
    "plt.ylabel('Neg Mean Squared',size=20,fontweight='bold')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "param_grid\n",
    "print(\"Best: %f using %s\" % (grid_result.best_score_,grid_result.best_params_))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Execute the final model: ExtraTrees(n_estimators:100) on the validation set\n",
    "\n",
    "from sklearn.ensemble import ExtraTreesRegressor\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "seed = 13\n",
    "ET = ExtraTreesRegressor(n_estimators=100,random_state=seed)\n",
    "ET.fit(X_train,Y_train)\n",
    "predictions = ET.predict(X_validation)\n",
    "print(mean_squared_error(Y_validation,predictions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix, classification_report\n",
    "from sklearn.metrics import explained_variance_score\n",
    "\n",
    "# print(explained_variance_score(Y_validation,predictions))\n",
    "# print(confusion_matrix(Y_validation,predictions))\n",
    "# print(classification_report(Y_validation,predictions))\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
